{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "class_names = ['Me', 'Not Me']\n",
    "\n",
    "model = load_model(os.path.join('Models', 'Face_MobNets50.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_image(img, x, y, w, h, i, k=0.1):\n",
    "    '''\n",
    "    Function, that return cropped image from 'img'\n",
    "    If k=0 returns image, cropped from (x, y) (top left) to (x+w, y+h) (bottom right)\n",
    "    If k!=0 returns image, cropped from (x-k*w, y-k*h) to (x+k*w, y+(1+k)*h)\n",
    "    \n",
    "    Parameters:\n",
    "        img : The original image\n",
    "        x : x coordinate of the upper-left corner\n",
    "        y : y coordinate of the upper-left corner\n",
    "        w : Width of the desired image\n",
    "        h : Height of the desired image\n",
    "        k : The coefficient of expansion of the image\n",
    "\n",
    "    Returns:\n",
    "        image (resized mage with extra dimension at axis=0 as a numpy array)\n",
    "    '''\n",
    "\n",
    "    # The next code block checks that coordinates will be non-negative\n",
    "    # (in case if desired image is located in top left corner)\n",
    "    if x - k*w > 0:\n",
    "        start_x = int(x - k*w)\n",
    "    else:\n",
    "        start_x = x\n",
    "    if y - k*h > 0:\n",
    "        start_y = int(y - k*h)\n",
    "    else:\n",
    "        start_y = y\n",
    "\n",
    "    end_x = int(x + (1 + k)*w)\n",
    "    end_y = int(y + (1 + k)*h)\n",
    "\n",
    "    face_image = img[start_y:end_y,\n",
    "                     start_x:end_x]\n",
    "   \n",
    "    face_image = cv2.resize(face_image, (224, 224))\n",
    "    face_image = face_image/255\n",
    "   \n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    face_image = np.expand_dims(face_image, axis=0)\n",
    "    \n",
    "    return face_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors to draw rectangles in BGR\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv object that will detect faces for us\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)  # webcamera\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Unable to access the camera\")\n",
    "else:\n",
    "    print(\"Access to the camera obtained\")\n",
    "\n",
    "print(\"Streaming started - to quit press ESC\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # for each face on the image detected obtaining the EXPANDED image\n",
    "\n",
    "        face_image = get_extended_image(frame, x, y, w, h, i, 0.5)\n",
    "        # classify face and draw a rectangle around the face\n",
    "        # green for positive class and red for negative\n",
    "        \n",
    "        result = model.predict(face_image)\n",
    "        \n",
    "        if float(result) > 0.5:\n",
    "            key = 1\n",
    "        else:\n",
    "            key = 0\n",
    "        prediction = class_names[np.array(key)]  # predicted class\n",
    "        confidence = np.array(result[0]).max(axis=0)  # degree of confidence\n",
    "\n",
    "        if prediction == 'Me':\n",
    "            color = GREEN\n",
    "        else:\n",
    "            color = RED\n",
    "        # draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        \n",
    "        cv2.putText(frame, \"{:6} - {:.2f}%\".format(prediction, confidence*100), (x, y), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)  \n",
    "\n",
    "    # display the resulting frame\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27:  # ESC code\n",
    "        break\n",
    "    # break\n",
    "\n",
    "# when everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
